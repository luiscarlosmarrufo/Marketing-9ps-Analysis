{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ollama\n",
    "import json\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\n",
    "    'PRODUCT', 'PLACE', 'PRICE', 'PUBLICITY', \n",
    "    'POSTCONSUMPTION', 'PURPOSE', 'PARTNERSHIPS', \n",
    "    'PEOPLE', 'PLANET'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   id                 120 non-null    int64 \n",
      " 1   text               120 non-null    object\n",
      " 2   date               120 non-null    object\n",
      " 3   likes              120 non-null    int64 \n",
      " 4   detected_language  120 non-null    object\n",
      " 5   tweet              120 non-null    object\n",
      " 6   PRODUCT            120 non-null    int64 \n",
      " 7   PLACE              120 non-null    int64 \n",
      " 8   PRICE              120 non-null    int64 \n",
      " 9   PUBLICITY          120 non-null    int64 \n",
      " 10  POSTCONSUMPTION    120 non-null    int64 \n",
      " 11  PURPOSE            120 non-null    int64 \n",
      " 12  PARTNERSHIPS       120 non-null    int64 \n",
      " 13  PEOPLE             120 non-null    int64 \n",
      " 14  PLANET             120 non-null    int64 \n",
      "dtypes: int64(11), object(4)\n",
      "memory usage: 14.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_x_selected.csv\")\n",
    "for category in CATEGORIES:\n",
    "    df[category] = 0\n",
    "    \n",
    "df.rename(columns={\"text_english\": \"tweet\"}, inplace=True)    \n",
    "df = df.head(120)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_batch(tweets, batch_size=10):\n",
    "    \"\"\"\n",
    "    Process multiple tweets in a single API call by constructing a batch prompt\n",
    "    \"\"\"\n",
    "    # Instantiate the Ollama client\n",
    "    client = ollama.Client()\n",
    "    \n",
    "    # Construct the categories string for the prompt\n",
    "    categories_str = \", \".join(CATEGORIES)\n",
    "    \n",
    "    # Construct a batch prompt that asks for classification of multiple tweets\n",
    "    batch_prompt = f\"\"\"\n",
    "You are an expert NLP classifier. Classify each tweet below into these categories: {categories_str}.\n",
    "For each tweet, determine if it belongs to each category (1) or not (0).\n",
    "Return your analysis in a valid JSON array where each item corresponds to one tweet in the same order:\n",
    "[\n",
    "  {{\"{CATEGORIES[0]}\": 0 or 1, \"{CATEGORIES[1]}\": 0 or 1, ..., \"{CATEGORIES[-1]}\": 0 or 1}},\n",
    "  {{\"{CATEGORIES[0]}\": 0 or 1, \"{CATEGORIES[1]}\": 0 or 1, ..., \"{CATEGORIES[-1]}\": 0 or 1}},\n",
    "  ...\n",
    "]\n",
    "\n",
    "Tweets to classify:\n",
    "\"\"\"\n",
    "    \n",
    "    # Add each tweet with an index\n",
    "    for i, tweet in enumerate(tweets):\n",
    "        batch_prompt += f\"\\n{i+1}. \\\"{tweet}\\\"\\n\"\n",
    "    \n",
    "    batch_prompt += \"\\nOnly output the JSON array with no additional text.\"\n",
    "    \n",
    "    # Make the API call\n",
    "    try:\n",
    "        result_str = client.chat(\n",
    "            model=\"llama3\",\n",
    "            messages=[{\"role\": \"user\", \"content\": batch_prompt}],\n",
    "            options={\"temperature\": 0}\n",
    "        )\n",
    "        \n",
    "        # Extract the content from the response\n",
    "        response_content = result_str['message']['content'].strip()\n",
    "        \n",
    "        # Find JSON in the response (in case model adds extra text)\n",
    "        import re\n",
    "        json_match = re.search(r'\\[.*\\]', response_content, re.DOTALL)\n",
    "        if json_match:\n",
    "            response_content = json_match.group(0)\n",
    "        \n",
    "        # Parse the JSON array\n",
    "        results = json.loads(response_content)\n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {e}\")\n",
    "        print(f\"Response content: {response_content if 'response_content' in locals() else 'No response'}\")\n",
    "        # Return default values for the batch\n",
    "        return [{category: 0 for category in CATEGORIES} for _ in tweets]\n",
    "\n",
    "def process_dataframe(df, batch_size=10):\n",
    "    \"\"\"\n",
    "    Process the entire dataframe in batches of specified size\n",
    "    \"\"\"\n",
    "    tweets = df['tweet'].tolist()\n",
    "    all_results = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in tqdm(range(0, len(tweets), batch_size)):\n",
    "        batch = tweets[i:i+batch_size]\n",
    "        batch_results = classify_batch(batch)\n",
    "        all_results.extend(batch_results)\n",
    "        \n",
    "        # Add a small delay to avoid overloading the API\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Update the dataframe with results\n",
    "    for i, result in enumerate(all_results):\n",
    "        if i < len(df):\n",
    "            for category in CATEGORIES:\n",
    "                df.at[i, category] = result.get(category, 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Option 2: Process using multithreading for even better performance\n",
    "def classify_tweet_mt(tweet):\n",
    "    \"\"\"Single tweet classification function for multithreading\"\"\"\n",
    "    client = ollama.Client()\n",
    "    \n",
    "    # Construct the categories string and JSON template for the prompt\n",
    "    categories_str = \", \".join(CATEGORIES)\n",
    "    json_template = \", \".join([f'\"{category}\": 0 or 1' for category in CATEGORIES])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are an expert NLP classifier. Given the tweet below, please determine which categories it belongs to among {categories_str}.\n",
    "Output the answer in JSON format exactly as:\n",
    "{{{json_template}}}\n",
    "\n",
    "Tweet: \"{tweet}\"\n",
    "Only output the JSON.\n",
    "\"\"\"\n",
    "    try:\n",
    "        result_str = client.chat(\n",
    "            model=\"llama3\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            options={\"temperature\": 0}\n",
    "        )\n",
    "        response_content = result_str['message']['content'].strip()\n",
    "        return json.loads(response_content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying tweet: {e}\")\n",
    "        return {category: 0 for category in CATEGORIES}\n",
    "\n",
    "def process_with_threading(df, max_workers=5):\n",
    "    \"\"\"Process tweets using multithreading\"\"\"\n",
    "    tweets = df['tweet'].tolist()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(tqdm(executor.map(classify_tweet_mt, tweets), total=len(tweets)))\n",
    "    \n",
    "    # Update the dataframe with results\n",
    "    for i, result in enumerate(results):\n",
    "        if i < len(df):\n",
    "            for category in CATEGORIES:\n",
    "                df.at[i, category] = result.get(category, 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [10:22<00:00, 51.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id                                               text  \\\n",
      "0    1902948287058973003  PEANUTS + STARBUCKS\\n\\nì´ë ‡ê²Œ ê·€ì—¬ìš´ ë§ˆì¹´ë¡±ì´ë¼ë‹ˆ!\\n#ìŠ¤ëˆ„í”¼ë§ˆì¹´...   \n",
      "1    1899431047382659156  Conversamos con una trabajadora de Starbucks e...   \n",
      "2    1902133288707485945  Soylatteð– šá\\n\\n#starbucks \\n#photo https://t.co...   \n",
      "3    1901929250351145424  ãƒªãƒ”å¤šã‚ã ã£ãŸãƒ”ã‚¶ãƒˆãƒ¼ã‚¹ãƒˆðŸ•ç¾Žå‘³ã—ã‹ã£ãŸãªãðŸ¤¤\\n#starbucks https://t....   \n",
      "4    1899628351528288580  ä»Šæ—¥ç™ºå£²ã®\\næ˜¥ç©ºãƒŸãƒ«ã‚¯ã‚³ãƒ¼ãƒ’ãƒ¼ãƒ•ãƒ©ãƒšãƒãƒ¼ãƒŽâ€¦\\nä¸­ã®ã‚¹ãƒˆãƒ­ãƒ™ãƒªãƒ¼ãƒœãƒ¼ãƒ«ã‚’\\nã‚¹ãƒˆãƒ­ãƒ¼ã§å‰²ã£...   \n",
      "..                   ...                                                ...   \n",
      "115  1016875474868363264  Plastic straws will soon be phased out of all ...   \n",
      "116  1825555363619574219  Starbucks is now trading at 25x earnings with ...   \n",
      "117  1732075961963729223  Remember to remember your reusable cup when yo...   \n",
      "118  1534133308891705300  1/ Emotional Connection\\n\\nEmosional brand yg ...   \n",
      "119  1534133926855266300  2/ Beli merchandise = loyalty\\n\\nMerchandise j...   \n",
      "\n",
      "                               date  likes detected_language  \\\n",
      "0    Fri Mar 21 05:00:01 +0000 2025      8                ko   \n",
      "1    Tue Mar 11 12:03:46 +0000 2025     17                es   \n",
      "2    Tue Mar 18 23:01:30 +0000 2025      4                en   \n",
      "3    Tue Mar 18 09:30:44 +0000 2025     16                ja   \n",
      "4    Wed Mar 12 01:07:47 +0000 2025    124                ja   \n",
      "..                              ...    ...               ...   \n",
      "115  Wed Jul 11 02:43:00 +0000 2018    334                en   \n",
      "116  Mon Aug 19 15:28:10 +0000 2024    133                en   \n",
      "117  Tue Dec 05 16:34:24 +0000 2023      6                en   \n",
      "118  Tue Jun 07 11:20:58 +0000 2022    783                id   \n",
      "119  Tue Jun 07 11:23:25 +0000 2022    572                id   \n",
      "\n",
      "                                                 tweet  PRODUCT  PLACE  PRICE  \\\n",
      "0    Peanuts + Starbucks\\n\\nThis cute macaroon!\\n#S...        1      1      0   \n",
      "1    We talked with a Starbucks worker on strike, w...        1      1      0   \n",
      "2    Soylatteð– šá\\n\\n#starbucks \\n#photo https://t.co...        1      0      0   \n",
      "3    Pizza toast was full of repliesðŸ•It was delicio...        1      1      0   \n",
      "4    Released today\\nSpring Sky Milk Coffee Frappuc...        1      0      0   \n",
      "..                                                 ...      ...    ...    ...   \n",
      "115  Plastic straws will soon be phased out of all ...        1      0      0   \n",
      "116  Starbucks is now trading at 25x earnings with ...        1      1      0   \n",
      "117  Remember to remember your reusable cup when yo...        1      0      0   \n",
      "118  1/ Emotional Connection\\n\\nEmotional brand tha...        1      0      0   \n",
      "119  2/ buy merchandise = loyalty\\n\\nMerchandise is...        1      0      0   \n",
      "\n",
      "     PUBLICITY  POSTCONSUMPTION  PURPOSE  PARTNERSHIPS  PEOPLE  PLANET  \n",
      "0            1                0        0             0       0       0  \n",
      "1            1                0        0             0       1       0  \n",
      "2            0                0        0             0       0       0  \n",
      "3            0                1        0             0       0       0  \n",
      "4            1                0        0             0       0       0  \n",
      "..         ...              ...      ...           ...     ...     ...  \n",
      "115          1                0        0             0       0       1  \n",
      "116          0                0        0             1       1       0  \n",
      "117          1                0        0             0       0       1  \n",
      "118          1                0        0             0       0       1  \n",
      "119          1                0        0             0       1       1  \n",
      "\n",
      "[120 rows x 15 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose your preferred method\n",
    "# Option 1: Use batch processing (recommended for most cases)\n",
    "result_df = process_dataframe(df, batch_size=10)\n",
    "\n",
    "# Option 2: Use multithreading (if your API can handle concurrent requests)\n",
    "# result_df = process_with_threading(df, max_workers=5)\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"df_x_classified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "id",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "likes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRODUCT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PLACE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PRICE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PUBLICITY",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "POSTCONSUMPTION",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PURPOSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PARTNERSHIPS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PEOPLE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PLANET",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a12c20be-2913-4a00-8ad8-5dfd1ad3f139",
       "rows": [
        [
         "count",
         "120.0",
         "120.0",
         "120.0",
         "120.0",
         "120.0",
         "120.0",
         "120.0",
         "120.0",
         "120.0",
         "120.0",
         "120.0"
        ],
        [
         "mean",
         "1.8143853595993073e+18",
         "324.01666666666665",
         "0.925",
         "0.31666666666666665",
         "0.1",
         "0.5833333333333334",
         "0.18333333333333332",
         "0.11666666666666667",
         "0.125",
         "0.5",
         "0.058333333333333334"
        ],
        [
         "std",
         "2.4938639219105805e+17",
         "2131.3447720946074",
         "0.26449571488641793",
         "0.4671266240679986",
         "0.3012578671520603",
         "0.527931325641733",
         "0.38856195407793426",
         "0.3223686843157241",
         "0.3321055820775357",
         "0.6736330697086078",
         "0.235355384180488"
        ],
        [
         "min",
         "1.0163248463707095e+18",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "25%",
         "1.900365982575773e+18",
         "2.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "50%",
         "1.9021061682202424e+18",
         "6.5",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "75%",
         "1.9028504010539996e+18",
         "21.5",
         "1.0",
         "1.0",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "0.0"
        ],
        [
         "max",
         "1.902948287058973e+18",
         "23052.0",
         "1.0",
         "1.0",
         "1.0",
         "2.0",
         "1.0",
         "1.0",
         "1.0",
         "3.0",
         "1.0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>likes</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>PLACE</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>PUBLICITY</th>\n",
       "      <th>POSTCONSUMPTION</th>\n",
       "      <th>PURPOSE</th>\n",
       "      <th>PARTNERSHIPS</th>\n",
       "      <th>PEOPLE</th>\n",
       "      <th>PLANET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.200000e+02</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.814385e+18</td>\n",
       "      <td>324.016667</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.058333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.493864e+17</td>\n",
       "      <td>2131.344772</td>\n",
       "      <td>0.264496</td>\n",
       "      <td>0.467127</td>\n",
       "      <td>0.301258</td>\n",
       "      <td>0.527931</td>\n",
       "      <td>0.388562</td>\n",
       "      <td>0.322369</td>\n",
       "      <td>0.332106</td>\n",
       "      <td>0.673633</td>\n",
       "      <td>0.235355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.016325e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.900366e+18</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.902106e+18</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.902850e+18</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.902948e+18</td>\n",
       "      <td>23052.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         likes     PRODUCT       PLACE       PRICE  \\\n",
       "count  1.200000e+02    120.000000  120.000000  120.000000  120.000000   \n",
       "mean   1.814385e+18    324.016667    0.925000    0.316667    0.100000   \n",
       "std    2.493864e+17   2131.344772    0.264496    0.467127    0.301258   \n",
       "min    1.016325e+18      0.000000    0.000000    0.000000    0.000000   \n",
       "25%    1.900366e+18      2.000000    1.000000    0.000000    0.000000   \n",
       "50%    1.902106e+18      6.500000    1.000000    0.000000    0.000000   \n",
       "75%    1.902850e+18     21.500000    1.000000    1.000000    0.000000   \n",
       "max    1.902948e+18  23052.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        PUBLICITY  POSTCONSUMPTION     PURPOSE  PARTNERSHIPS      PEOPLE  \\\n",
       "count  120.000000       120.000000  120.000000    120.000000  120.000000   \n",
       "mean     0.583333         0.183333    0.116667      0.125000    0.500000   \n",
       "std      0.527931         0.388562    0.322369      0.332106    0.673633   \n",
       "min      0.000000         0.000000    0.000000      0.000000    0.000000   \n",
       "25%      0.000000         0.000000    0.000000      0.000000    0.000000   \n",
       "50%      1.000000         0.000000    0.000000      0.000000    0.000000   \n",
       "75%      1.000000         0.000000    0.000000      0.000000    1.000000   \n",
       "max      2.000000         1.000000    1.000000      1.000000    3.000000   \n",
       "\n",
       "           PLANET  \n",
       "count  120.000000  \n",
       "mean     0.058333  \n",
       "std      0.235355  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      0.000000  \n",
       "max      1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
